# 🧠 Neural Networks: Zero to Hero — My Implementations & Notes

This repository contains my personal journey through [Andrej Karpathy's *Neural Networks: Zero to Hero*](https://karpathy.ai/zero-to-hero.html) lecture series.  
I’m following along, coding everything from scratch, and documenting the insights I gain while building neural networks from the ground up.

---

## 📂 Contents

- **Lecture 1 — Micrograd**  
  Build a tiny autograd engine from scratch.

- **Lecture 2 — MLP from Scratch**  
  Implement a basic multi-layer perceptron without deep learning libraries.

- **Lecture 3 — Makemore**  
  Train a character-level language model.

- **Lecture 4 — GPT from Scratch**  
  Build a Transformer architecture inspired by GPT.

- **Lecture 5+ — Scaling Up**  
  Optimization, training tricks, and scaling models.

---

## 🎯 Goals of This Project
- Understand neural networks **deeply**, not just use them.
- Write every core component from scratch.
- Apply Karpathy’s philosophy: *“Learn by building.”*
- Share well-documented, clean, and reproducible code.

---

## 🛠️ Tech Stack
- **Language:** Python 3.x  
- **Libraries:** Numpy, PyTorch (only when needed), Matplotlib  
- **Tools:** Jupyter Notebook for interactive exploration

---